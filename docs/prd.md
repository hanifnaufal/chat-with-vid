# Chat with Video Product Requirements Document (PRD)
## Goals and Background Context
#### Goals
- **Showcase Full-Stack & LLM Expertise**: Create a high-quality, open-source project that serves as a professional portfolio piece, demonstrating advanced skills in modern full-stack web development and practical LLM integration.

- **Build a Community Asset**: Develop a tool that is genuinely useful to the community, attracting engagement and establishing a positive reputation.

- **Encourage Collaboration**: Foster a small but active community by making the project easy to set up and contribute to, highlighting skills in creating maintainable codebases.

- **High Utility**: Ensure the tool is actively used when run locally, proving its real-world value.

- **Developer Friendliness**: A new contributor can successfully set up the local development environment and run tests in under 30 minutes.

#### Background Context
The primary problem this project addresses is the inefficiency of retrieving specific information from long-form educational or informational YouTube videos. Users like students, researchers, and professionals often need precise answers or summaries but are forced to manually scrub through video timelines, which is time-consuming and cumbersome.

This project proposes a web application that transforms the passive viewing experience into an interactive, queryable knowledge base. By inputting a YouTube URL, users can engage in a conversational chat with the video's content, asking questions and receiving context-aware answers generated by an LLM (Gemini). This provides a significant advantage over existing solutions like static transcripts or basic summarizers by allowing for deep, interactive exploration of the video's content.

## Requirements
#### Functional
- **FR1**: The system must provide an interface for a user to submit a YouTube video URL.

- **FR2**: The backend must process a submitted URL to retrieve the video's transcript and prepare it for analysis by the Gemini API.

- **FR3**: In addition to the transcript, the backend must retrieve the video's metadata, including its title, thumbnail URL, channel name, view count, and publication date.

- **FR4**: Upon successful video processing, the application must automatically generate and display an ** and a list of actionable items derived from the video's content.

- **FR5**: The system must feature an interactive chat interface that displays the conversation history and allows the user to submit new questions.

- **FR6**: The system must integrate with the Gemini API, sending the video transcript as context along with the user's question, and stream the generated response back to the chat interface.

- **FR7**: The application must persist conversations on the user's local machine. The UI must display a list of past chats, with each entry showing the video's thumbnail, title, channel name, view count, and relative published date (e.g., '2 months ago'). Users must be able to reopen a conversation from this list.

- **FR8**: The project must include a README.md file with clear, step-by-step instructions for setting up the local development environment and configuring the necessary Gemini API key.

- **FR9**: After a video is processed, the system should suggest a few relevant questions the user can ask to start the conversation, based on the video's title and transcript.

- **FR10**: The LLM's responses during the chat must be based solely on the context provided by the video's transcript and should not answer questions on unrelated topics.

#### Non-Functional
- **NFR1**: The application must be responsive and function correctly on modern desktop and mobile web browsers (Chrome, Firefox, Safari, Edge).

- **NFR2**: For a 10-minute video, the initial summary must be generated in under 10 seconds, and chat responses must begin streaming in under 3 seconds.

- **NFR3**: The system must be built using React/Next.js for the frontend, Python/FastAPI for the backend, and PostgreSQL for the database.

- **NFR4**: The Gemini API key must be managed securely via an environment variable (.env file) and must not be exposed in the frontend code.

- **NFR5**: The MVP must be capable of running entirely on a user's local machine, with an operational budget of zero.

- **NFR6**: The system must include safeguards and safety measures to mitigate prompt injection attacks at the API level.

- **NFR7**: A new contributor must be able to set up the local development environment and run all tests successfully in under 30 minutes by following the project documentation.

## User Interface Design Goals
#### Overall UX Vision
The user experience should be clean, fast, and conversational. The primary goal is to make a complex backend process feel simple and intuitive. Users should feel like they are interacting with a knowledgeable assistant who is an expert on the video's content. The interface must prioritize clarity and efficiency, getting the user from a URL to an answer with the least possible friction.

#### Key Interaction Paradigms
- **Conversational Interface**: The core interaction will be a standard chat UI (like a messaging app) with a user input field at the bottom and a scrolling history of questions and answers.

- **Streaming Responses**: To enhance the feeling of a live conversation and meet performance goals (NFR2), answers from the LLM will stream in token by token.

- **Suggested Actions**: To guide users, the interface will present clickable "suggested questions" (FR9) after the initial summary is generated.

#### Core Screens and Views
- **Home/Input Screen**: A minimalist page with a single, clear call-to-action: a text input field for the user to paste a YouTube URL and a "Process Video" button.

- **Analysis/Chat Screen**: The main workspace. It will initially display the video's metadata and the generated summary/actionables (FR4, FR7). Below this, the interactive chat interface will allow for conversation.

- **Chat History Screen**: A view that displays the list of saved conversations, showing the rich metadata for each (thumbnail, title, channel, etc., as per FR7). Clicking an item will navigate the user to the Analysis/Chat Screen for that video.

#### Accessibility: WCAG AA
To ensure the application is usable by the widest possible audience and reflects a high-quality portfolio piece, the target will be WCAG 2.1 Level AA compliance.

#### Branding
Branding for the MVP will be minimal, focusing on a clean, modern, and trustworthy aesthetic that prioritizes content and usability. The color palette should be simple (e.g., a primary blue for interactive elements, with dark text on a light background) to ensure high readability.

#### Target Device and Platforms: Web Responsive
The application will be designed with a mobile-first, responsive approach to ensure a seamless experience on both desktop and mobile web browsers.

## Technical Assumptions
#### Repository Structure: Monorepo
The project will be structured as a monorepo. This approach is recommended in the project brief to keep the Python backend and Next.js frontend code together in a single, portfolio-ready package, simplifying dependency management and cross-platform development.

#### Service Architecture: Decoupled Client-Server
The application will be built with a decoupled architecture where the Next.js frontend acts as the client and the Python/FastAPI application serves as the backend API server. The final deployment target (e.g., monolithic server, serverless functions) is deferred and will be decided after the local MVP is complete.

#### Testing Requirements: Unit + Integration
The testing strategy for the MVP will focus on a combination of Unit and Integration tests. This ensures that individual components function correctly and that the frontend and backend can communicate as expected. A full end-to-end (E2E) testing suite will be considered a post-MVP addition to maintain a focused initial scope.

#### Additional Technical Assumptions and Requests
The following technologies are specified in the project brief and are considered foundational assumptions for the architecture:

- **Frontend**: React with Next.js
- **Backend**: Python with FastAPI
- **Database**: PostgreSQL (specifically managed with Docker for local development)
- **LLM**: Google's Gemini API

## Epic List
#### Epic 1: Foundation & Core Video Chat
**Epic Goal**: To establish the complete project foundation, process a YouTube video to retrieve its transcript and metadata, and enable a user to have a live, context-aware conversation with its content. By the end of this epic, a user can input a URL, receive an initial analysis, and have a complete chat session.

##### Story 1.1: Project Scaffolding & Setup
As a developer,
I want a complete project structure with all necessary dependencies and a local database,
so that I can begin developing features in a consistent and reproducible environment.

**Acceptance Criteria**:
- A monorepo is created containing separate packages for the api (FastAPI) and web (Next.js) applications.
- All dependencies listed in the technical assumptions (Next.js, FastAPI, etc.) are installed.
- A docker-compose.yml file is created to run a PostgreSQL database locally.
- The web and api applications can be started successfully with a single command.
- A README.md file is created with clear instructions for the initial setup (as per FR8).

##### Story 1.2: Continuous Integration Workflow
As a developer,
I want a GitHub Actions workflow that automatically runs checks on every pull request,
so that I can ensure code quality, maintainability, and prevent regressions from being merged into the main branch.

**Acceptance Criteria**
- A new GitHub Actions workflow file is created in .github/workflows/.
- The workflow automatically triggers on any pull request targeting the main branch.
- The workflow installs dependencies for both the api (Python) and web (Next.js) applications.
- The workflow runs all linter checks (e.g., Ruff/Black for Python, ESLint/Prettier for the frontend).
- The workflow executes the complete unit and integration test suite (as defined in your Technical Assumptions).
- The workflow must successfully pass before a pull request is permitted to be merged (requires configuration of branch protection rules in GitHub).



##### Story 1.3: Backend API for Video Chat Creation
As an Efficient Learner,
I want to submit a YouTube URL to the application,
so that a new chat can be created and processed.

**Acceptance Criteria**:
- A FastAPI endpoint POST /api/chats is created that accepts a YouTube URL.
-  The endpoint creates a new chat record, kicks off an asynchronous job to process the video, and immediately returns a unique chat_id.
- The asynchronous job retrieves the video's transcript (FR2) and metadata (FR3).
- The job saves the transcript and metadata associated with the chat record.
- The endpoint handles errors gracefully (e.g., invalid URL) and returns an appropriate error message.

##### Story 1.4: Frontend URL Submission & Asynchronous Polling
As an Efficient Learner,
I want to paste a YouTube URL into the app and get immediate feedback,
so that I can see my request is being handled without blocking the interface.

**Acceptance Criteria**:
- The home page contains a single input field for a YouTube URL and a "Process" button (FR1).
- When the "Process" button is clicked, a POST request is sent to the /api/chats endpoint.
- Upon receiving a chat_id, the application navigates to the analysis page (/chat/{chat_id}).
- The analysis page immediately displays a loading state and begins polling a new endpoint, GET /api/chats/{chat_id},  to check the processing status.
- The loading state must be descriptive, showing the user the current stage of the process (e.g., "Step 1/3: Fetching transcript...", "Step 2/3: Analyzing content...", "Step 3/3: Generating summary...").
- If the API returns an error during submission, a user-friendly error message is displayed.

##### Story 1.5: Display Initial Analysis & Video Player
As an Efficient Learner,
I want to see the initial summary, suggested questions, and the video player when processing is complete,
so that I can get immediate value and have context for my chat.

**Acceptance Criteria**:
- A new backend endpoint GET /api/chats/{chat_id} returns the chat status (processing, complete, or failed) and, if  complete, the full analysis payload.
- A new backend job uses the Gemini API to generate a summary, actionable items (FR4), and suggested questions (FR9) and saves them to the chat record.
- The analysis page displays an embedded YouTube video player snippet for the current video.
- When the polling status becomes complete, the loading state is replaced with the video's metadata, the insightful summary, actionable items, and a list of clickable, suggested questions.
- The information on the page must have a clear visual hierarchy: the insightful summary and suggested questions should be the most prominent elements, followed by the chat interface, with the video player and metadata servingas secondary contextual information.

##### Story 1.6: Implement Core Chat Functionality
As an Efficient Learner,
I want to ask questions in a chat interface and receive answers based on the video,
so that I can interactively explore the content.

**Acceptance Criteria**:
- A chat input field is available on the analysis screen (FR5).
- A new backend endpoint POST /api/chats/{chat_id}/messages is created that accepts a user's question.
- The endpoint sends a properly formatted prompt to the Gemini API, using the chat's transcript for context and instructing it to only answer based on that context (FR10).
- The response from the Gemini API is streamed back to the frontend and displayed in the chat window (FR6).
- The conversation history of the current session is displayed in a scrolling view.
- A clear visual cue (e.g., a pulsing input field or a temporary message like "Ask me anything!") prompts the user to begin the chat.
- While the AI response is streaming, a "Stop Generating" button is visible and functional, allowing the user to interrupt the response.

#### Epic 2: Local Chat Persistence and History
**Epic Goal**: To build the persistence layer for the application, allowing users to save their conversations and analysis locally. This involves setting up the database schema, creating backend APIs to save and retrieve chats, and building the frontend interface to browse and reopen past conversations.

##### Story 2.1: Backend Persistence Logic & Schema
As a developer,
I want to define the database schema and save a completed video analysis and chat history to the local PostgreSQL database,
so that user conversations are not lost between application sessions.

Acceptance Criteria:
- A database schema is created in PostgreSQL for storing chats (including all video metadata, the transcript, and the generated analysis) and chat_messages.
- After a video's analysis is successfully generated, the complete chat data is saved to the chats table.
- Each individual user question and AI response from a chat is saved to the chat_messages table, linked to the correct chat.

##### Story 2.2: Backend API for Retrieving Chat History
As an Efficient Learner,
I want to retrieve a list of all my past conversations,
so that I can see my history at a glance.

Acceptance Criteria:
- A new endpoint, GET /api/chats, is created.
- The endpoint retrieves all saved chats from the database.
- The endpoint returns a JSON array of chats, with each object containing the rich metadata required for the history list (thumbnail, title, channel name, view count, and relative published date, as per FR7).

##### Story 2.3: Frontend History UI & Navigation
As an Efficient Learner,
I want to view a history page with all my past chats,
so that I can easily find and select a previous conversation to review.

Acceptance Criteria:
- A new "History" page is created in the frontend application, accessible from the main navigation.
- When the page loads, it calls the GET /api/chats endpoint to fetch the list of past conversations.
- The list is displayed in a user-friendly format, rendering the thumbnail, title, channel name, etc., for each item as required by FR7.
- Each item in the list is a link that navigates the user to the analysis/chat page for that specific chat (e.g., /chat/{chat_id}).

##### Story 2.4: Hydrating the Chat View with Past Conversations
As an Efficient Learner,
I want to click on a past chat in my history and see the full conversation,
so that I can continue where I left off or review the information.

Acceptance Criteria:
- The GET /api/chats/{chat_id} endpoint is updated to also return the saved chat messages for that chat.
- When the analysis/chat page loads with a chat_id, it fetches the complete chat data, including the past conversation.
- The chat view is pre-populated with the entire saved conversation history, appearing exactly as it did when the session was last active.

## Checklist Results Report
#### Executive Summary
- **Overall PRD Completeness**: 100%
- **MVP Scope Appropriateness**: Just Right
- **Readiness for Architecture Phase**: Ready
- **Most Critical Gaps or Concerns**: None. The interactive refinement process has addressed potential gaps effectively.

#### Category Statuses

| Category | Status | Critical Issues |
| --- | --- | --- |
| 1. Problem Definition & Context | ✅ PASS | None |
| 2. MVP Scope Definition | ✅ PASS | None |
| 3. User Experience Requirements | ✅ PASS | None |
| 4. Functional Requirements | ✅ PASS | None |
| 5. Non-Functional Requirements | ✅ PASS | None |
| 6. Epic & Story Structure | ✅ PASS | None |
| 7. Technical Guidance | ✅ PASS | None |
| 8. Cross-Functional Requirements | ✅ PASS | None |
| 9. Clarity & Communication | ✅ PASS | None |

**Final Decision: ✅ READY FOR ARCHITECT**: The PRD and epics are comprehensive, properly structured, and ready for the UI/UX and architectural design phases.